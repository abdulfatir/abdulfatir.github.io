<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Abdul Fatir Ansari</title> <meta name="author" content="Abdul Fatir Ansari"> <meta name="description" content="Abdul Fatir Ansari, Machine Learning Scientist "> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%93%88&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://abdulfatir.com//"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks</a> </li> <li class="nav-item "> <a class="nav-link" href="/poems/">poems</a> </li> <li class="nav-item"> <a class="nav-link" href="https://drive.google.com/open?id=1T9tMY1NQQTTFE2sIYXjuVDUIufE5xXB6" target="_blank" rel="external nofollow noopener">cv</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Abdul Fatir</span> Ansari </h1> <p class="desc"><b>Senior Applied Scientist</b> at AWS</p> </header> <article> <div class="profile float-right"> <figure> <picture> <img src="/assets/img/prof_pic.webp?36b7004f74ebc3ca445c4c02fba4990c" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.webp" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Hallo! I am Fatir, a Machine Learning Scientist at Amazon Web Services (AWS) based in Berlin, where I work on time series forecasting, log analytics, and generative models. Of late, I have been working on building general purpose models (aka “foundation” models) for time series problems. I also contribute to AWS’ open source libraries: <a href="https://auto.gluon.ai/" rel="external nofollow noopener" target="_blank">AutoGluon</a> and <a href="https://ts.gluon.ai/" rel="external nofollow noopener" target="_blank">GluonTS</a>.</p> <p><strong>Research</strong>: My general research interest lies in the areas of <strong>time series analysis</strong> and <strong>generative models</strong>, encompassing probabilistic generative modeling, unsupervised learning, and representation learning. For details about my background and research, please take a look at my <a href="https://drive.google.com/open?id=1T9tMY1NQQTTFE2sIYXjuVDUIufE5xXB6" target="_blank" rel="external nofollow noopener">curriculum vitae</a> and my <a href="https://scholar.google.com/citations?user=BZ0EoqIAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">google scholar page</a>.</p> <p><strong>Previously</strong>: I graduated with a <strong>PhD in Computer Science</strong> from <a href="https://www.comp.nus.edu.sg/" rel="external nofollow noopener" target="_blank">NUS School of Computing</a> where I was advised by Prof. <a href="https://haroldsoh.github.io" rel="external nofollow noopener" target="_blank">Harold Soh</a> and received the <em>Dean’s Graduate Research Excellence Award</em> for my PhD research. Prior to that, I obtained my bachelor’s degree in Civil Engineering from <a href="https://www.iitr.ac.in" rel="external nofollow noopener" target="_blank">IIT Roorkee</a>. During my undergrad years, I also participated in Google Summer of Code in 2016 and 2017.</p> <p><strong>Contact</strong>: abdulfatirs [at] gmail [dot] com</p> <div class="row" id="affiliations-logos"> <div class="col-3"> <div class="logo-wrap"> <span class="helper"></span> <a href="//www.amazon.science" target="_blank"><img src="/assets/img/logos/amazon.webp"></a> </div> <div class="logo-desc"> AWS AI<br> 2021, 2022 - Present </div> </div> <div class="col-3"> <div class="logo-wrap"> <span class="helper"></span> <a href="//www.comp.nus.edu.sg/" target="_blank"><img src="/assets/img/logos/nus.webp" alt="NUS Logo"></a> </div> <div class="logo-desc"> NUS School of Computing<br> 2017 - 2022 </div> </div> <div class="col-3"> <div class="logo-wrap"> <span class="helper"></span> <a href="//www.iitr.ac.in/" target="_blank"><img src="/assets/img/logos/iitr.webp"></a> </div> <div class="logo-desc"> IIT Roorkee<br> 2013 - 2017 </div> </div> <div class="col-3"> <div class="logo-wrap"> <span class="helper"></span> <a href="//summerofcode.withgoogle.com/" target="_blank"><img src="/assets/img/logos/gsoc.png"></a> </div> <div class="logo-desc"> Google Summer of Code<br> S2016, S2017 </div> </div> </div> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Aug 2025</th> <td> Delivered a lecture on <em>Building Foundation Models for Time Series</em> at the <a href="https://https://www.oxfordml.school/" rel="external nofollow noopener" target="_blank">Oxford ML School</a>. </td> </tr> <tr> <th scope="row">Jul 2025</th> <td> Chronos models have crossed <strong>500 million downloads</strong> (all time) on <a href="https://huggingface.co/collections/amazon/chronos-models-and-datasets-65f1791d630a8d57cb718444" rel="external nofollow noopener" target="_blank">Hugging Face</a>! </td> </tr> <tr> <th scope="row">Jul 2025</th> <td> Gave a talk on <a href="https://github.com/autogluon/autogluon" rel="external nofollow noopener" target="_blank">AutoGluon-TimeSeries</a> and <a href="https://github.com/awslabs/graphstorm" rel="external nofollow noopener" target="_blank">GraphStorm</a> at the ICML Expo. </td> </tr> <tr> <th scope="row">May 2025</th> <td> Our paper on <a href="https://arxiv.org/abs/2412.05244" rel="external nofollow noopener" target="_blank">wavelet-based tokenization for time series foundation mdoels</a> got accepted at ICML. </td> </tr> <tr> <th scope="row">Jan 2025</th> <td> Our paper on <a href="https://arxiv.org/abs/2503.12107" rel="external nofollow noopener" target="_blank">lightweight covariate adapters for pretrained models</a> got accepted at AISTATS. </td> </tr> </table> </div> </div> <h2><a href="/blog/" style="color: inherit;">latest posts</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Dec 24, 2020</th> <td> <a class="news-title" href="/blog/2020/Gradient-Flows/">Introduction to Gradient Flows in the 2-Wasserstein Space</a> </td> </tr> <tr> <th scope="row">Apr 17, 2020</th> <td> <a class="news-title" href="/blog/2020/Langevin-Monte-Carlo/">Monte Carlo Sampling using Langevin Dynamics</a> </td> </tr> <tr> <th scope="row">Apr 8, 2020</th> <td> <a class="news-title" href="/blog/2020/Wasserstein-Distance/">1-Wasserstein distance: Kantorovich–Rubinstein duality</a> </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">TMLR</abbr></div> <div id="ansari2024chronos" class="col-sm-8"> <div class="title">Chronos: Learning the Language of Time Series</div> <div class="author"> <em>Abdul Fatir Ansari</em>, <a href="https://lostella.github.io/" rel="external nofollow noopener" target="_blank">Lorenzo Stella</a>, <a href="https://caner.io/" rel="external nofollow noopener" target="_blank">Caner Turkmen</a>, <a href="https://xiyuanzh.github.io/" rel="external nofollow noopener" target="_blank">Xiyuan Zhang</a>, Pedro Mercado, <a href="https://huibinshen.github.io/" rel="external nofollow noopener" target="_blank">Huibin Shen</a>, <a href="https://shchur.github.io/" rel="external nofollow noopener" target="_blank">Oleksandr Shchur</a>, Syama Syndar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, Jasper Zschiegner, <a href="https://dcmaddix.github.io/" rel="external nofollow noopener" target="_blank">Danielle C. Maddix</a>, <a href="http://wanghao.in/" rel="external nofollow noopener" target="_blank">Hao Wang</a>, <a href="https://www.stat.berkeley.edu/~mmahoney/" rel="external nofollow noopener" target="_blank">Michael W. Mahoney</a>, Kari Torkkola, <a href="https://cims.nyu.edu/~andrewgw/" rel="external nofollow noopener" target="_blank">Andrew Gordon Wilson</a>, Michael Bohlke-Schneider, and <a href="https://www.mit.edu/~ywang02/" rel="external nofollow noopener" target="_blank">Bernie Wang</a> </div> <div class="periodical"> <em>Transactions on Machine Learning Research</em>, 2024 </div> <div class="highlight"> 3.5K Github stars and 500M+ Hugging Face model downloads as of Aug 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2403.07815" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/amazon-science/chronos-forecasting" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>We introduce Chronos, a simple yet effective framework for pretrained probabilistic time series models. Chronos tokenizes time series values using scaling and quantization into a fixed vocabulary and trains existing transformer-based language model architectures on these tokenized time series via the cross-entropy loss. We pretrained Chronos models based on the T5 family (ranging from 20M to 710M parameters) on a large collection of publicly available datasets, complemented by a synthetic dataset that we generated via Gaussian processes to improve generalization. In a comprehensive benchmark consisting of 42 datasets, and comprising both classical local models and deep learning methods, we show that Chronos models: (a) significantly outperform other methods on datasets that were part of the training corpus; and (b) have comparable and occasionally superior zero-shot performance on new datasets, relative to methods that were trained specifically on them. Our results demonstrate that Chronos models can leverage time series data from diverse domains to improve zero-shot accuracy on unseen forecasting tasks, positioning pretrained models as a viable tool to greatly simplify forecasting pipelines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ansari2024chronos</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Chronos: Learning the Language of Time Series}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ansari, Abdul Fatir and Stella, Lorenzo and Turkmen, Caner and Zhang, Xiyuan and Mercado, Pedro and Shen, Huibin and Shchur, Oleksandr and Rangapuram, Syama Syndar and Pineda Arango, Sebastian and Kapoor, Shubham and Zschiegner, Jasper and Maddix, Danielle C. and Wang, Hao and Mahoney, Michael W. and Torkkola, Kari and Wilson, Andrew Gordon and Bohlke-Schneider, Michael and Wang, Bernie}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Transactions on Machine Learning Research}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2835-8856}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=gerNCVqqtR}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{3.5K Github stars and 500M+ Hugging Face model downloads as of Aug 2025}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICML</abbr> <span class="award badge">Oral</span> </div> <div id="ansari2023neural" class="col-sm-8"> <div class="title">Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series</div> <div class="author"> <em>Abdul Fatir Ansari</em>, <a href="https://ajrheng.github.io/" rel="external nofollow noopener" target="_blank">Alvin Heng</a>, Andre Lim, and <a href="https://haroldsoh.github.io" rel="external nofollow noopener" target="_blank">Harold Soh</a> </div> <div class="periodical"> <em>In International Conference on Machine Learning</em>, 2023 </div> <div class="highlight"> Oral Presentation (top 2.4%) </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2301.11308" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/clear-nus/NCDSSM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Learning accurate predictive models of real-world dynamic phenomena (e.g., climate, biological) remains a challenging task. One key issue is that the data generated by both natural and artificial processes often comprise time series that are irregularly sampled and/or contain missing observations. In this work, we propose the Neural Continuous-Discrete State Space Model (NCDSSM) for continuous-time modeling of time series through discrete-time observations. NCDSSM employs auxiliary variables to disentangle recognition from dynamics, thus requiring amortized inference only for the auxiliary variables. Leveraging techniques from continuous-discrete filtering theory, we demonstrate how to perform accurate Bayesian inference for the dynamic states. We propose three flexible parameterizations of the latent dynamics and an efficient training objective that marginalizes the dynamic states during inference. Empirical results on multiple benchmark datasets across various domains show improved imputation and forecasting performance of NCDSSM over existing models.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ansari2023neural</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ansari, Abdul Fatir and Heng, Alvin and Lim, Andre and Soh, Harold}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pubtype</span> <span class="p">=</span> <span class="s">{Oral}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Oral Presentation (top 2.4%)}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">NeurIPS</abbr></div> <div id="kollovieh2023predict" class="col-sm-8"> <div class="title">Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting</div> <div class="author"> <a href="https://marcelkollovieh.de/" rel="external nofollow noopener" target="_blank">Marcel Kollovieh*</a>, <em>Abdul Fatir Ansari*</em>, Michael Bohlke-Schneider, Jasper Zschiegner, <a href="http://wanghao.in/" rel="external nofollow noopener" target="_blank">Hao Wang</a>, and <a href="https://www.mit.edu/~ywang02/" rel="external nofollow noopener" target="_blank">Yuyang Wang</a> </div> <div class="periodical"> <em>In Neural Information Processing Systems</em>, 2023 </div> <div class="highlight"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2307.11494" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Diffusion models have achieved state-of-the-art performance in generative modeling tasks across various domains. Prior works on time series diffusion models have primarily focused on developing conditional models tailored to specific forecasting or imputation tasks. In this work, we explore the potential of task-agnostic, unconditional diffusion models for several time series applications. We propose TSDiff, an unconditionally trained diffusion model for time series. Our proposed self-guidance mechanism enables conditioning TSDiff for downstream tasks during inference, without requiring auxiliary networks or altering the training procedure. We demonstrate the effectiveness of our method on three different time series tasks: forecasting, refinement, and synthetic data generation. First, we show that TSDiff is competitive with several task-specific conditional forecasting methods (predict). Second, we leverage the learned implicit probability density of TSDiff to iteratively refine the predictions of base forecasters with reduced computational overhead over reverse diffusion (refine). Notably, the generative performance of the model remains intact – downstream forecasters trained on synthetic samples from TSDiff outperform forecasters that are trained on samples from other state-of-the-art generative time series models, occasionally even outperforming models trained on real data (synthesize).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kollovieh2023predict</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kollovieh*, Marcel and Ansari*, Abdul Fatir and Bohlke-Schneider, Michael and Zschiegner, Jasper and Wang, Hao and Wang, Yuyang}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing Systems}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"><abbr class="badge">ICLR</abbr></div> <div id="Ansari2021RefiningDG" class="col-sm-8"> <div class="title">Refining Deep Generative Models via Discriminator Gradient Flow</div> <div class="author"> <em>Abdul Fatir Ansari</em>, <a href="https://neoanarika.github.io/" rel="external nofollow noopener" target="_blank">Ming Liang Ang</a>, and <a href="https://haroldsoh.github.io" rel="external nofollow noopener" target="_blank">Harold Soh</a> </div> <div class="periodical"> <em>In International Conference on Learning Representations</em>, 2021 </div> <div class="highlight"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2012.00780" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://clear-nus.github.io/blog/dgflow" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Blog</a> <a href="https://github.com/clear-nus/DGflow" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Deep generative modeling has seen impressive advances in recent years, to the point where it is now commonplace to see simulated samples (e.g., images) that closely resemble real-world data. However, generation quality is generally inconsistent for any given model and can vary dramatically between samples. We introduce Discriminator Gradient flow (DGflow), a new technique that improves generated samples via the gradient flow of entropy-regularized f-divergences between the real and the generated data distributions. The gradient flow takes the form of a non-linear Fokker-Plank equation, which can be easily simulated by sampling from the equivalent McKean-Vlasov process. By refining inferior samples, our technique avoids wasteful sample rejection used by previous methods (DRS &amp; MH-GAN). Compared to existing works that focus on specific GAN variants, we show our refinement approach can be applied to GANs with vector-valued critics and even other deep generative models such as VAEs and Normalizing Flows. Empirical results on multiple synthetic, image, and text datasets demonstrate that DGflow leads to significant improvement in the quality of generated samples for a variety of generative models, outperforming the state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator Driven Latent Sampling (DDLS) methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Ansari2021RefiningDG</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Refining Deep Generative Models via Discriminator Gradient Flow}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ansari, Abdul Fatir and Ang, Ming Liang and Soh, Harold}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://scholar.google.com/citations?user=BZ0EoqIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/abdulfatir" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/abdulfatir" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/solitarypenman" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> The best way to reach me is via email. </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Abdul Fatir Ansari. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams",inlineMath:[["$","$"],["\\(","\\)"]],processEscapes:!0}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-MF3HZJPRL1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-MF3HZJPRL1");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>